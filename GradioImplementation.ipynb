{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Before anything, run this cell first\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "vGsudGiNwlwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dafd84b-b989-47b4-fc39-4dcdd97b9909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_resnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6PitDjsIsGZ",
        "outputId": "3b6d79ff-a937-4468-d57a-cb3634d06c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_resnet\n",
            "  Downloading keras-resnet-0.2.0.tar.gz (9.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.10/dist-packages (from keras_resnet) (2.14.0)\n",
            "Building wheels for collected packages: keras_resnet\n",
            "  Building wheel for keras_resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20457 sha256=9c1c6f6f2fd5a87174c4d0e62ba255e1df85d750c416d2b1033e682d1bc286d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/af/88/a668b279c5eadbe55dcaf6207f09059135166cefb09088bacc\n",
            "Successfully built keras_resnet\n",
            "Installing collected packages: keras_resnet\n",
            "Successfully installed keras_resnet-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/ME781/Project/keras-retinanet\")"
      ],
      "metadata": {
        "id": "GbfWFym-xRdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from termcolor import colored\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "import keras_resnet\n",
        "import cv2"
      ],
      "metadata": {
        "id": "MT4pnjmartbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jrtE9KSotgK"
      },
      "outputs": [],
      "source": [
        "def defect_detection(image_file):\n",
        "  model_file_path = \"/content/drive/MyDrive/ME781/Project/defect_detection/defect_detection_vgg16.hdf5\"\n",
        "  model = load_model(model_file_path)\n",
        "\n",
        "  # setting image dimensions\n",
        "  image_width = 224\n",
        "  image_height = 224\n",
        "  labels = {0: \"Defective\", 1: \"Not Defective\"}\n",
        "\n",
        "  # load and pre-process the image\n",
        "  img = image.load_img(image_file, target_size=(image_width, image_height))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "  # run the image through the defect detection model to obtain the predictions\n",
        "\n",
        "  out = model.predict(x)\n",
        "  pred = np.argmax(out[0])\n",
        "  return labels[pred]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def defect_classification(image_file):\n",
        "  model_file_path = \"/content/drive/MyDrive/ME781/Project/defect_classification/defect_classification_vgg16.hdf5\"\n",
        "  model = load_model(model_file_path)\n",
        "\n",
        "  # setting image dimensions\n",
        "  image_width = 224\n",
        "  image_height = 224\n",
        "  labels = {0: \"Crazing\", 1: \"Inclusion\", 2: \"Patches\", 3: \"Pitted\", 4: \"Rolled\", 5: \"Scratches\"}\n",
        "\n",
        "  # load and pre-process the image\n",
        "  img = image.load_img(image_file, target_size=(image_width, image_height))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "  # run the image through the defect detection model to obtain the predictions\n",
        "\n",
        "  out = model.predict(x)\n",
        "  pred = np.argmax(out[0])\n",
        "  return labels[pred]"
      ],
      "metadata": {
        "id": "djtKAdyyta2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def object_detection(image_file, labels_to_names = {0: \"pump_impeller\"}):\n",
        "\n",
        "  model_file_path = \"/content/drive/MyDrive/ME781/Project/object_detection/pump_impeller_detection_retinanet.h5\"\n",
        "  model = models.load_model(model_file_path, backbone_name = \"resnet50\")\n",
        "  threshold = 0.7\n",
        "\n",
        "  # read and pre-process the image\n",
        "  image = read_image_bgr(image_file)\n",
        "  draw = image.copy()\n",
        "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "  image = preprocess_image(image)\n",
        "  image, scale = resize_image(image)\n",
        "  x = np.expand_dims(image, axis = 0)\n",
        "\n",
        "  # obtain the bounding boxes for the objects detected in the image and correct their scale\n",
        "  boxes, scores, labels = model.predict_on_batch(x)\n",
        "  boxes /= scale\n",
        "\n",
        "  # store the bounding box details for valid detection (i.e. confidence > threshold)\n",
        "  bounding_boxes = {}\n",
        "  count = 0\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "\n",
        "    # scores are sorted in descending order hence we can 'break' out of the loop when we reach below threshold for the first time\n",
        "    if score < threshold:\n",
        "      break\n",
        "\n",
        "    color = label_color(label)\n",
        "\n",
        "    b = box.astype(int)\n",
        "    draw_box(draw, b, color=color)\n",
        "\n",
        "    caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "    draw_caption(draw, b, caption)\n",
        "\n",
        "  return draw"
      ],
      "metadata": {
        "id": "VKsujWN5uYKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "defect_detection_interface = gr.Interface(fn = defect_detection, inputs = gr.Image(type=\"filepath\"), outputs=\"text\", title=\"Identify and elimate product defects using computer vision and AI\", description=\"Check out the glimse of our defect detection model which uses computer vision and CNNs to identify the relevant parts from an image and classify them to be either defective or good quality.\")\n",
        "defect_classification_interface = gr.Interface(fn = defect_classification, inputs = gr.Image(type=\"filepath\"), outputs=\"text\", title=\"Localize and classify the type of defects in manufactured parts\", description=\"Try out our defect classifier model which can predict the types of defect that a product may have based on the image using deep CNNs trained using transfer learning. This feature allows you to classify the different types of defects on metal surfaces into 6 different categories.\")\n",
        "object_detection_interface = gr.Interface(fn = object_detection, inputs = gr.Image(type=\"filepath\"), outputs=\"image\", title=\"Identify the presence of an object using computer vision and AI\", description=\"Check out our object detection model which leverages CNNs to identify the presence of an object and classifies it accordingly\")"
      ],
      "metadata": {
        "id": "XNrI9GEZzlFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_interface = gr.TabbedInterface(interface_list=[object_detection_interface, defect_detection_interface, defect_classification_interface],\n",
        "                         tab_names = [\"Object Detection Interface\", \"Defect Detection Interface\", \"Defect Classification Interface\"],\n",
        "                                     title=\"MechDefect Solutions\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    final_interface.launch(share=True, inline = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxHFEkzHOH3D",
        "outputId": "cdba0381-4855-4926-f39e-540c7b29b2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://daac75c92c7df59721.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ]
    }
  ]
}